

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon_half.png">
  <link rel="icon" href="/img/favicon_half.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="lx_tyin">
  <meta name="keywords" content="">
  
    <meta name="description" content="专业数学基础">
<meta property="og:type" content="article">
<meta property="og:title" content="专业数学基础">
<meta property="og:url" content="http://www.lxtyin.ac.cn/2024/12/06/%E4%B8%93%E4%B8%9A%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="lx_tyin">
<meta property="og:description" content="专业数学基础">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lxtyin.ac.cn/img/math/qr1.png">
<meta property="og:image" content="https://lxtyin.ac.cn/img/math/svd1.png">
<meta property="og:image" content="https://lxtyin.ac.cn/img/math/matrix1.png">
<meta property="og:image" content="https://lxtyin.ac.cn/img/math/dcx1.png">
<meta property="og:image" content="https://lxtyin.ac.cn/img/math/dcx2.png">
<meta property="article:published_time" content="2024-12-05T16:00:00.000Z">
<meta property="article:modified_time" content="2024-12-26T15:08:52.047Z">
<meta property="article:author" content="lx_tyin">
<meta property="article:tag" content="数理基础">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://lxtyin.ac.cn/img/math/qr1.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>专业数学基础 - lx_tyin</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"www.lxtyin.ac.cn","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":4},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>lx_tyin</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-friends"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/welcome-cover.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="专业数学基础"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-12-06 00:00" pubdate>
          2024年12月6日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">专业数学基础</h1>
            
            
              <div class="markdown-body">
                
                <p><span class="math display">\[
\newcommand{\vec}{\mathbf}
\newcommand{\eps}{\varepsilon}
\]</span></p>
<h3 id="线性代数">线性代数</h3>
<h4 id="线性变换">线性变换</h4>
<p>对空间中的每个点作变换后，轴保持平行等距，原点不变。</p>
<p>upd：更广义的说法是线性映射（离散数学中的映射）：空间 <span
class="math inline">\(V\)</span> 变换到空间 <span
class="math inline">\(W\)</span>
（这里的空间可以是任何广义的空间）后，保持加法和数乘运算。</p>
<p>线性映射本身也具有加法、数乘和乘法性质： <span
class="math display">\[
\begin{gather*}
S,T均为空间V到W的线性映射，K为U到V的映射 \\
(S+T)(v) = S(v) +T(v) \\
(\lambda T)(v) = \lambda(T(v))  \\
SK(u) = S(K(u))
\end{gather*}
\]</span> （线性映射不具有交换律，一定将零元映射到零元）</p>
<p>线性映射可能降维，但不可能升维。</p>
<p>线性映射 <span class="math inline">\(T\)</span> 可能将一些向量映射到0
<span class="math inline">\(T(v) = 0\)</span>，这些向量被称为 <span
class="math inline">\(T\)</span> 的零空间 <span
class="math inline">\(\mathrm{null} T\)</span>。</p>
<p>线性映射若不降维（等价于 <span class="math inline">\(\mathrm{null} T
=
\{0\}\)</span>），则它必定是单射、满射、可逆（即线性变换），我们称之为<strong>同构</strong></p>
<p>单射+满射 = 可逆 = 满秩 = 同构</p>
<p>我们说”从空间 <span class="math inline">\(V\)</span> 到 <span
class="math inline">\(W\)</span> 的线性映射 <span
class="math inline">\(T\)</span> “时，并不意味着 <span
class="math inline">\(W\)</span>
中的每个元素都能被映射到。能被映射到的部分称为值域 <span
class="math inline">\(\mathrm{range}T\)</span>，它是 <span
class="math inline">\(W\)</span> 的一个子空间。 <span
class="math display">\[
dim(V) = dim(\mathrm{range}T) + dim(\mathrm{null}T)
\]</span></p>
<h4 id="线性泛函">线性泛函</h4>
<p>空间 <span class="math inline">\(V\rightarrow \mathbf F\)</span>
的线性映射称之为 <span class="math inline">\(V\)</span>
的线性泛函，这可以是任意广义的空间上的线性映射，例如 <span
class="math inline">\(\varphi(p) = \int p(x)dx\)</span> 是多项式空间
<span class="math inline">\(\mathcal{P}\)</span> 上的线性泛函。</p>
<h4 id="对偶基">对偶基</h4>
<p>由 <span class="math inline">\(n\)</span> 维线性空间 <span
class="math inline">\(V\)</span> 到一维数域 <span
class="math inline">\(F\)</span> 的映射称为线性泛函，它可以用一个 <span
class="math inline">\(n\)</span> 维向量表示。所有的线性泛函构成了 <span
class="math inline">\(n\)</span> 维空间 <span
class="math inline">\(V&#39;\)</span>，它是 <span
class="math inline">\(V\)</span> 的<strong>对偶空间</strong>。</p>
<p>设 <span class="math inline">\(v_1,..v_n\)</span> 是 <span
class="math inline">\(V\)</span> 的一组基（不必正交），<span
class="math inline">\(\phi_1,..\phi_n\)</span> 是 <span
class="math inline">\(V&#39;\)</span> 中的向量组，满足 <span
class="math inline">\(\phi_i(v_j) = \delta_{ij}\)</span>，则 <span
class="math inline">\(\phi_1,..\phi_n\)</span> 是 <span
class="math inline">\(v_1,..v_n\)</span>
的<strong>对偶基</strong>。对偶基是对偶空间的基。</p>
<h3 id="矩阵分解">矩阵分解</h3>
<h4 id="lu分解">LU分解</h4>
<p>对于可逆方阵 <span class="math inline">\(\vec
A\)</span>，我们进行高斯消元，将其表示为若干个初等矩阵和一个上三角矩阵的乘积，<span
class="math inline">\(\vec A = \vec E_1 \vec E_2..\vec U = \vec L \vec
U\)</span></p>
<p>高斯消元的过程如果始终是自上而下递推的，则显然 <span
class="math inline">\(\vec L\)</span>
是一个下三角矩阵。这就是矩阵的LU分解。我们可以进行额外的缩放变换，使得
<span class="math inline">\(\vec L\)</span> 的对角线元素都为1。</p>
<p>消元时可能无法避免行交换，那么可以先对 <span
class="math inline">\(\vec A\)</span> 进行行交换再分解： <span
class="math display">\[
\begin{gather*}
\vec P\vec A = \vec L \vec U \\
\vec A = \vec P^{-1}\vec L \vec U \\
\end{gather*}
\]</span></p>
<h4 id="cholesky分解">Cholesky分解</h4>
<p>（TOBE UPDATED）</p>
<p>对称正定矩阵必然可以分解为 <span class="math inline">\(\vec A = \vec
L \vec L^T\)</span>，<span class="math inline">\(\vec L\)</span>
是一个下三角矩阵，对角线上元素均大于0。</p>
<p>不难发现 <span class="math inline">\(\vec A_{uv} = \sum_{k=1}^{n}
\vec L_{uk}\vec L_{vk}\)</span></p>
<p>我们可以从左到右、从上到下地计算 <span
class="math inline">\(L\)</span> <span class="math display">\[
\begin{gather*}
L_{vv}^2 =A_{vv} - \sum_{k=1}^{v-1} L_{vk} \\
L_{vv}L_{uv} = A_{vv} - \sum_{k=1}^{v-1} L_{uk} L_{vk},(u\ge v)
\end{gather*}
\]</span></p>
<h4 id="qr分解">QR分解</h4>
<p><img src="https://lxtyin.ac.cn/img/math/qr1.png" srcset="/img/loading.gif" lazyload /></p>
<p>QR分解有完全QR分解和约化QR分解，如图所示。</p>
<p>约化形式：<span class="math inline">\(\vec A_{m\times n} = \vec
Q_{m\times n} \vec R_{n\times n}\)</span>，<span
class="math inline">\(\vec Q\)</span> 为列正交矩阵，<span
class="math inline">\(\vec R\)</span> 为上三角矩阵。</p>
<p>完全形式即约化形式在 <span class="math inline">\(\vec Q\)</span>
上扩充正交基。</p>
<p>任意列满秩矩阵 <span class="math inline">\(\vec A\)</span>
一定存在上述两种QR分解。</p>
<blockquote>
<p>对于任意秩为 <span class="math inline">\(r\)</span> 的矩阵 <span
class="math inline">\(\vec A\)</span>，也存在一种QR分解（暂略）。</p>
</blockquote>
<p><strong>Gram-Schmidt正交化</strong></p>
<p>将 <span class="math inline">\(\vec A\)</span> 的 <span
class="math inline">\(n\)</span> 个列向量 <span
class="math inline">\(\vec a_1,..\vec a_n\)</span> 投影到正交基 <span
class="math inline">\(\pmb\eps_1,..\pmb\eps_n\)</span> 上。首先令 <span
class="math inline">\(\pmb\eps_1 = \frac{\vec a_1}{||\vec
a_1||}\)</span>，然后令后续所有 <span class="math inline">\(\vec
a\)</span> 减去与 <span class="math inline">\(\pmb\eps_1\)</span>
平行的分量 <span class="math display">\[
\vec a_i \leftarrow \vec a_i - (\vec a_i^T\pmb\eps_i)\pmb\eps_i
\]</span> 随后 <span class="math inline">\(\pmb\eps_2 = \frac{\vec
a_2}{||\vec a_2||}\)</span>，以此类推。</p>
<p>最终 <span class="math inline">\(\vec Q =
[\pmb\eps_1,...\pmb\eps_n]\)</span>。</p>
<p>上式实际上可以看做对 <span class="math inline">\(\vec A\)</span>
的一系列初等变换，每一步都是先归一化第 <span
class="math inline">\(i\)</span> 列（等价于整列除 <span
class="math inline">\(||\vec a_i||\)</span> ），再令右侧每一列减去 <span
class="math inline">\((\vec a_j^T\pmb\eps_i)\)</span> 倍的第 <span
class="math inline">\(i\)</span>
列。这一系列初等变换构成的是一个上三角矩阵。（注意列变换的初等矩阵应该乘在右边）
<span class="math display">\[
\vec A (\vec E_1...\vec E_k) = \vec Q
\]</span> <span class="math inline">\(\vec R\)</span>
即为这个初等变换的逆矩阵，仍然是上三角矩阵。实际算时有 <span
class="math inline">\(\vec R = \vec Q^T\vec A\)</span>（因为 <span
class="math inline">\(\vec Q^T\vec Q = \vec I\)</span>）</p>
<p><strong>Householder变换</strong></p>
<p>Householder矩阵：<span class="math inline">\(\vec H = \vec I - 2\vec
u\vec u^T\)</span>，这个矩阵表示的是沿“以单位向量 <span
class="math inline">\(\vec u\)</span> 为法线的 <span
class="math inline">\(n-1\)</span> 维超平面”的镜像变换矩阵，代入 <span
class="math inline">\(\vec x\)</span> 计算一下 <span
class="math inline">\(\vec H\vec x\)</span> 容易理解。</p>
<p><span class="math inline">\(\vec H\)</span>
有许多性质，都比较容易理解：<span class="math inline">\(\vec H = \vec
H^{-1}\)</span>，<span class="math inline">\(\vec H\)</span>
是正交的，特征值为 <span class="math inline">\(1,-1\)</span>。</p>
<p>对于任意向量 <span class="math inline">\(\vec
x\)</span>，一定存在某个Householder变化将其映射到 <span
class="math inline">\(\pm||\vec x|| \vec e_1\)</span>，<span
class="math inline">\(\vec e_1\)</span> 为标准单位向量（易得）</p>
<p>以 <span class="math inline">\(\vec x_1 &gt; 0\)</span>
为例，我们会选取 <span class="math inline">\(\vec u = \vec x + ||\vec
x|| \vec e_1\)</span> 对应的变换，这实际上是将其映射到了 <span
class="math inline">\(-\vec e_1\)</span> 方向上，这样反着映射能让 <span
class="math inline">\(\vec u\)</span> 尽可能大，保证数值稳定（计算 <span
class="math inline">\(\vec H\)</span> 的时候需要单位化 <span
class="math inline">\(\vec u\)</span>）。</p>
<p><strong>利用Householder进行QR分解</strong></p>
<p>对于任意方阵 <span class="math inline">\(\vec A = (\vec a_1, ..\vec
a_n)\)</span>，首先取 <span class="math inline">\(\vec H_1\vec a_1 = k_1
\vec e_1\)</span>，这里的 <span class="math inline">\(k_1 = \pm||\vec
a_1||\)</span>，依据上述原则取正负。</p>
<p><span class="math inline">\(\vec A \vec H_1\)</span>
得到的结果第一列为 <span class="math inline">\(k_1\vec
e_1\)</span>，再取其右下角 <span class="math inline">\(n-1\)</span>
阶子式作为 <span class="math inline">\(\vec
A_2\)</span>，进行下一步。</p>
<p>下一步同理，得到 <span class="math inline">\(\vec{\hat
H_2}\)</span>（<span class="math inline">\(n-1\)</span> 阶），再令 <span
class="math display">\[
\vec H_2 = \left[
\begin{gather*}
\vec I &amp;0 \\
0  &amp;\vec{\hat H_2}
\end{gather*}
\right]
\]</span> 得到 <span class="math inline">\(n\)</span> 阶的 <span
class="math inline">\(\vec H_2\)</span>，这个 <span
class="math inline">\(\vec H_2\)</span> 同样是一个householder矩阵。</p>
<p>如此这般，最终得到 <span class="math inline">\(\vec H_{n-1} ..\vec
H_1\vec A = \vec R\)</span>，形成了一个上三角矩阵。</p>
<p><span class="math inline">\(\vec Q = (\vec H_{n-1} ..\vec
H_1)^{-1}\)</span></p>
<h4 id="奇异值分解">奇异值分解</h4>
<p>对于列满秩矩阵 <span class="math inline">\(\vec A_{m\times
n}\)</span>，它将 <span class="math inline">\(n\)</span>
维空间的单位球投影到 <span class="math inline">\(m\)</span>
维超椭球上，其中，单位球上的正交轴 <span class="math inline">\(\vec
v_1,..\vec v_n\)</span> 分别投影到椭球上的正交主轴 <span
class="math inline">\(\sigma_1 \vec u_1,..\sigma_n\vec u_n\)</span>，即
<span class="math inline">\(\vec A \vec v_i = \sigma_i \vec
u_i\)</span></p>
<p><span class="math inline">\(\vec v_i\)</span> 称为右奇异向量，<span
class="math inline">\(\vec u_i\)</span> 为左奇异向量，<span
class="math inline">\(\sigma_i\)</span> 为奇异值 <span
class="math display">\[
\begin{align*}
设 \quad &amp;\pmb\Sigma = diag(\sigma_1,.. \sigma_n) \\
&amp; \vec V = (\vec v_1,..\vec v_n) \\
&amp; \vec U = (\vec u_1,..\vec u_n) \\
则 \quad &amp;\vec A\vec V = \vec U \pmb\Sigma \\
&amp;\vec A_{m\times n} = \vec U_{m\times n} \pmb\Sigma_{n\times n} \vec
V^{T}_{n\times n}
\end{align*}
\]</span> 这是约化奇异值分解，我们也可以将其扩充成完全奇异值分解： <span
class="math display">\[
\vec A_{m\times n} = \vec U_{m\times m} \pmb\Sigma_{m\times n} \vec
V^{T}_{n\times n}
\]</span></p>
<p>如何计算 <span class="math inline">\(\vec U\)</span> 和 <span
class="math inline">\(\vec V\)</span>？ <span class="math display">\[
\vec A^T\vec A = (\vec V \pmb\Sigma^T \vec U^{T}) (\vec U \pmb\Sigma
\vec V^{T}) = \vec V \pmb\Sigma^2 \vec V^T
\]</span> 这个式子很熟悉，我们可以发现 <span class="math inline">\(\vec
A^T \vec A\)</span> 的特征向量组即为 <span class="math inline">\(\vec
V\)</span>，特征值即为 <span
class="math inline">\(\pmb\Sigma^2\)</span>。同理我们可以得出 <span
class="math inline">\(\vec A\vec A^T\)</span> 的特征向量组即为 <span
class="math inline">\(\vec U\)</span>。</p>
<p>由于 <span class="math inline">\(\pmb\Sigma\)</span>
实际上是一堆特征值，我们可以随便改它们的顺序；将其从大到小排序后，往往前面少数几个奇异值就占据了99%以上的比例，这就可以来做压缩。</p>
<ul>
<li><p>最大奇异值表示了矩阵的能够放大向量的最大倍数，这也是矩阵的2-范数，<span
class="math inline">\(||\vec A||_2 = \sigma_1\)</span>；</p></li>
<li><p>矩阵的F-范数类似向量的长度，为所有元素平方和开根， <span
class="math display">\[
||\vec A||^2_F = \sum_{i=1}^m(\vec A \vec A^T)_{i,i} = tr(\vec A \vec
A^T) = \sum_{i=1}^n\sigma^2_{i}
\]</span> 这里用到了：对角线之和 = 迹 = 特征值之和 = <span
class="math inline">\(\pmb\Sigma^2\)</span> 元素和。</p></li>
</ul>
<p><strong>非满秩情况</strong></p>
<p>对于非列满秩的矩阵，也可以进行SVD，会得到一些零奇异向量，</p>
<p>（特征值分解时，零特征值也会对应若干组线性不相关的特征向量？TOBE
CHECK）</p>
<p>设有 <span class="math inline">\(r\)</span> 个非零奇异向量（等价于
<span class="math inline">\(\vec A\vec A^T\)</span> 有 <span
class="math inline">\(r\)</span> 个非零特征值）：</p>
<p><img src="https://lxtyin.ac.cn/img/math/svd1.png" srcset="/img/loading.gif" lazyload /></p>
<p>图中可以看出，实际上有用的部分就只有 <span class="math inline">\(\vec
V, \vec U\)</span> 的前 <span class="math inline">\(r\)</span>
列，因此有： <span class="math display">\[
\vec A_{m\times n} = \vec U&#39;_{m\times r} \Sigma&#39;_{r\times r}
\vec V&#39;^T_{r\times n}
\]</span> 这里我们用 <span class="math inline">\(&#39;\)</span>
表示矩阵中起作用的子式。</p>
<ul>
<li><span class="math inline">\(\vec A\)</span> 的列空间等于 <span
class="math inline">\(\vec U&#39;_{m\times r}\)</span> 张成的空间；$A $
的零空间等于 <span class="math inline">\(\vec V\)</span> 的 <span
class="math inline">\(r+1,..n\)</span> 列张成的空间。</li>
</ul>
<h3 id="多元统计分析">多元统计分析</h3>
<h4 id="协方差"><strong>协方差</strong></h4>
<p>复习一下：</p>
<p>协方差表达了两个随机变量的线性相关性： <span class="math display">\[
\begin{gather*}
Cov(X, Y) = E((X-\overline X)(Y-\overline Y)) \\
Cov(X, X) = D(X)
\end{gather*}
\]</span>
协方差可以为正或者负，两变量线性不相关时，协方差为0（注意不相关不等于独立，它们还可以有非线性的相关性）</p>
<p>协方差矩阵，即对于 <span class="math inline">\(n\)</span> 个随机变量
<span class="math inline">\(X_1,..X_n\)</span>，<span
class="math inline">\(\Sigma_{i,j} = Cov(X_i,
X_j)\)</span>，包含了所有随机变量的两两协方差，显然，协方差矩阵是一个实对称矩阵，它的特征向量彼此正交。</p>
<p>协方差矩阵的特征值和特征向量有重要的几何意义，考虑 <span
class="math inline">\(m\)</span> 个 <span
class="math inline">\(n\)</span> 维样本（每一维对应一个随机变量 <span
class="math inline">\(X_i\)</span>）构成 <span
class="math inline">\(m\times n\)</span> 的样本矩阵 <span
class="math inline">\(\vec
A\)</span>，不失一般性地，假设所有样本均值为0。</p>
<p>于是 <span class="math inline">\(\Sigma = \frac{1}{m} \vec A^T\vec
A\)</span>，考虑它的特征向量： <span class="math display">\[
\begin{gather*}
\Sigma x = \lambda x \\
\vec A^T \vec A x = m \lambda x \\
(\vec Ax)^T(\vec Ax) = m\lambda x^Tx = m\lambda
\end{gather*}
\]</span> <span class="math inline">\(\vec Ax\)</span>
实际上是所有样本点与 <span class="math inline">\(x\)</span>
作点乘，<span class="math inline">\((\vec Ax)^T(\vec Ax)\)</span>
表示所有点在 <span class="math inline">\(x\)</span>
方向的投影的平方之和，<span class="math inline">\(\lambda\)</span>
也就是在 <span class="math inline">\(x\)</span> 方向上的方差。</p>
<p>结论：协方差矩阵的最大特征值对应的特征向量即为点集分布方差最大的方向（点云朝向）；最小的方向即为法向。</p>
<h4 id="多元随机向量"><strong>多元随机向量</strong></h4>
<p>设 <span class="math inline">\(\vec X\)</span> 为随机向量组 <span
class="math inline">\([\vec x_1,..\vec x_p]^T\)</span></p>
<p>它的期望也是 <span class="math inline">\(p\times 1\)</span>
的向量组，方差是协方差矩阵： <span class="math display">\[
\begin{gather*}
D(\vec X) = E((\vec X - \vec{\overline X})(\vec X - \vec{\overline
X})^T) \\
D(\vec X)_{i,j} = Cov(\vec X_i, \vec X_j)
\end{gather*}
\]</span> 这里方差的定义和单随机变量的定义类似，只不过用 <span
class="math inline">\(\vec A\vec A^T\)</span> 的形式代替了平方。</p>
<p>两个随机向量之间的协方差也可以构成协方差矩阵，但需注意这种矩阵不是方阵。
<span class="math display">\[
\begin{gather*}
Cov(\vec X, \vec Y) = E((\vec X - \vec{\overline X})(\vec Y -
\vec{\overline Y})^T)  \\
Cov(\vec X, \vec Y)_{i,j} = Cov(\vec X_i, \vec Y_j)
\end{gather*}
\]</span> 两个随机向量 <span class="math inline">\(\vec X, \vec
Y\)</span> 组合成一个新随机向量，其协方差矩阵为： <span
class="math display">\[
\Sigma = \left[
\begin{align*}
Cov(\vec X, \vec X), Cov(\vec X, \vec Y) \\
Cov(\vec Y, \vec X), Cov(\vec Y, \vec Y) \\
\end{align*}
\right] \\
\]</span></p>
<p>可以看出随机变量的性质可以很好地扩展到多元，并且仍然符合原有的定义。</p>
<p>一些性质： <span class="math display">\[
\begin{gather*}
E(\vec A\vec X) = \vec A E(\vec X) \\
D(\vec A\vec X) = \vec A D(\vec X) \vec A^T \\
Cov(\vec A\vec X, \vec B\vec Y) = \vec A Cov(\vec X, \vec Y) \vec B^T
\end{gather*}
\]</span> 运用原始定义比较容易证明。</p>
<p>协方差矩阵是实对称、半正定的（将 <span class="math inline">\(\vec y^T
\Sigma \vec y\)</span> 代入原始定义易证）。那么 <span
class="math inline">\(\Sigma\)</span> 可相似对角化，并且有任意特征值
<span class="math inline">\(\ge 0\)</span>： $$ <span
class="math display">\[\begin{gather*}
\Sigma = \vec U\Lambda \vec U^T = (\vec U \sqrt \Lambda\vec U^T)^2 =
\vec L \vec L^T, \quad (\vec L = \vec L^T)\\

\end{gather*}\]</span> $$</p>
<p>这说明了协方差矩阵可以”开根“，在 <span
class="math inline">\(\Sigma\)</span> 正定时，<span
class="math inline">\(\vec L\)</span> 必定是满秩的。</p>
<h4 id="多元正态分布">多元正态分布</h4>
<p>一个 <span class="math inline">\(p\)</span> 维的多元正态分布 <span
class="math inline">\(\vec X\)</span> 是由 <span
class="math inline">\(q\)</span> 个相互独立的标准正态分布 <span
class="math inline">\(U_1,..U_q \sim N(0, 1)\)</span> 线性组合而成的：
<span class="math display">\[
\vec A_{p\times q} \vec U_{q\times 1} + \pmb\mu_{p \times 1} = \vec
X_{p\times 1} \sim N_p(\pmb\mu, \vec A\vec A^T)
\]</span> 这是多元正态分布的定义，注意在这之中，<span
class="math inline">\(U_{1..q}\)</span>
是相互独立的标准正态分布，它们按照 <span class="math inline">\(\vec
A\)</span> 线性组合形成了 <span class="math inline">\(\vec X\)</span>
中的 <span class="math inline">\(p\)</span>
个随机变量，它们之间是有关联的，协方差为 <span
class="math inline">\(\vec A \vec A^T\)</span>（容易证明）。</p>
<p>这说明，多元正态分布的各个变量虽然相互有关，但它们的关系是很简单的，只是一批独立标准正态分布的不同组合。</p>
<p>多元正态分布重新进行任意线性组合，得到的仍为多元正态分布。 <span
class="math display">\[
\begin{gather*}
\vec X \sim N_p(\pmb\mu, \Sigma) \\
\vec B_{s\times p} \vec X + \vec d \sim N_s(\pmb B\pmb\mu+\vec d, \vec
B\Sigma \vec B^T)
\end{gather*}
\]</span>
多元正态分布的任意边缘分布也是正态分布。但一个分布的任意边缘分布为正态分布，不能导出该分布是多元正态分布；一个随机向量的任意线性组合都为一元正态分布，可以推出该随机向量是正态随机向量。</p>
<p>多元正态分布的联合概率密度函数： $$ <span
class="math display">\[\begin{gather*}
\vec X \sim N_p(\pmb\mu, \Sigma) \\
f(\vec X) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp(-\frac{1}{2}(\vec
X - \pmb\mu)^T\Sigma^{-1}(\vec X - \pmb\mu))

\end{gather*}\]</span> $$ 符合这种概率密度函数 <span
class="math inline">\(\leftrightarrow\)</span> 是多元正态分布。</p>
<h4 id="随机矩阵">随机矩阵</h4>
<p>从 <span class="math inline">\(p\)</span> 元随机向量 <span
class="math inline">\(\vec X\)</span> 中取 <span
class="math inline">\(n\)</span> 个样本，构成 <span
class="math inline">\(n\times p\)</span> 的样本矩阵，称为随机矩阵 <span
class="math inline">\(\vec X&#39;\)</span>。</p>
<p>我们先不将样本确定化，随机矩阵仍然视为一个 <span
class="math inline">\(n\times p\)</span>
维的长随机向量，可以把它拉直来看：</p>
<p><img src="https://lxtyin.ac.cn/img/math/matrix1.png" srcset="/img/loading.gif" lazyload /></p>
<p>拉直后的随机向量的均值和协方差矩阵如图所示，注意两次不同采样之间是独立的，因此两个样本间的协方差为0。</p>
<p>若 <span class="math inline">\(\vec X \sim N_p(\pmb\mu,
\Sigma)\)</span>，则随机阵拉直后的随机向量 <span
class="math inline">\(Vec(\vec X&#39;)\)</span> 也是一个多元正态分布：
<span class="math display">\[
Vec(\vec X&#39;) \sim N_{n\times p}(\vec 1_{n} \otimes \pmb\mu, \vec
I_{n} \otimes \Sigma)
\]</span> 图示见上，也可以把 <span
class="math inline">\(\pmb\mu\)</span> 也罗列成一个矩阵 <span
class="math inline">\(\vec M\)</span>： <span class="math display">\[
\vec X_{n\times p}&#39; \sim N_{n\times p}(\vec M_{n\times p}, \vec
I_n\otimes \Sigma)
\]</span> 称随机阵 <span class="math inline">\(\vec X&#39;\)</span>
服从<strong>矩阵正态分布</strong>。</p>
<ul>
<li>Kronecker积，直积：由 <span class="math inline">\(\vec A\)</span>
中的每一个元素乘以 <span class="math inline">\(\vec
B\)</span>，再罗列成一个大矩阵：<span class="math inline">\(\vec
A_{n\times p}\otimes\vec B_{m\times q} = \vec C_{nm\times
pq}\)</span></li>
<li><span class="math inline">\(\vec 1_n\)</span> 为长度为 <span
class="math inline">\(n\)</span> 的列向量，值全为1；<span
class="math inline">\(\vec I_n\)</span> 为 <span
class="math inline">\(n\)</span> 阶单位矩阵。</li>
</ul>
<h4 id="样本矩阵">样本矩阵</h4>
<p>现在将样本确定下来，已有一个 <span class="math inline">\(n\times
p\)</span> 的样本矩阵 <span class="math inline">\(\vec
X\)</span>（确定值），如何从中估计参数？</p>
<p>均值 <span class="math inline">\(\vec{\overline X}_{p\times 1} =
\frac{1}{n}\vec X^T \vec 1_n\)</span></p>
<p>样本离差矩阵：<span class="math inline">\(\vec A = \vec{\tilde X^T}
\vec{\tilde X}\)</span>，其中 <span class="math inline">\(\vec{\tilde
X}\)</span> 为减去均值后的样本矩阵</p>
<p>协方差矩阵：<span class="math inline">\(\vec S = \frac{1}{n-1} \vec
A\)</span></p>
<p>相关系数矩阵：按相关系数定义计算即可 <span
class="math inline">\(\rho(X, Y) = \frac{COV(X, Y)}{\sigma_X
\sigma_Y}\)</span>，嫌麻烦就不写成矩阵形式了）</p>
<p>可以通过样本矩阵，对多元正态总体的 <span class="math inline">\(\pmb
\mu, \Sigma\)</span>
进行最大似然估计（用到多元正态总体的联合概率密度，略）。</p>
<h3 id="回归分析">回归分析</h3>
<p>标准线性回归模型：有样本矩阵 <span class="math inline">\(\vec
X_{n\times m}\)</span>，每个样本对应一个标签（因变量），标签矩阵 <span
class="math inline">\(\vec Y_{n\times
1}\)</span>，要求样本与标签的线性关系（或尽可能近似的线性关系） <span
class="math display">\[
\begin{gather*}
\vec Y = \vec C \pmb\beta + \pmb\eps \\
\vec C = [\vec 1_n, \vec X], \quad \pmb\beta = [\beta_0,..\beta_m]^T
\end{gather*}
\]</span> 其中 <span class="math inline">\(\pmb\eps\)</span>
衡量误差。对于不同的样本，误差也不尽相同，因此我们认为 <span
class="math inline">\(\pmb\eps\)</span> 是一个不可观测的随机变量，<span
class="math inline">\(\pmb\eps \sim N_n(0, \sigma^2\vec
I_n)\)</span>。（这个式子说的是general的情况，代入样本矩阵后，每一个样本对应的误差是确定值）</p>
<p>可以认为 <span class="math inline">\(\vec{\hat Y} = \vec C
\pmb\beta\)</span> 为预测值， <span class="math inline">\(\vec
Y\)</span> 为真实值，该模型假设误差符合正态分布。</p>
<p>在给定样本阵和标签阵下，要使误差 <span class="math inline">\(\vec Y -
\vec C\pmb\beta\)</span> 尽可能小，按照最小二乘法 <span
class="math inline">\(Q(\pmb\beta) = (\vec Y - \vec C\pmb\beta)^T(\vec Y
- \vec C\pmb\beta)\)</span>，使 <span
class="math inline">\(Q(\pmb\beta)\)</span> 的一阶导为0： <span
class="math display">\[
\begin{gather*}
\frac{\part Q}{\part \pmb\beta} = -2(\vec Y - \vec C\pmb\beta)^T\vec C =
0\\
\pmb\beta = (\vec C^T\vec C)^{-1}\vec C^T\vec Y
\end{gather*}
\]</span> 设 <span class="math inline">\(\vec b = (\vec C^T\vec
C)^{-1}\vec C^T\vec Y\)</span> 为 <span
class="math inline">\(\pmb\beta\)</span> 的最小二乘估计量。</p>
<p>由 <span class="math inline">\(\vec Y \sim N_n(\vec C\pmb\beta,
\sigma^2\vec I_n)\)</span>，得 <span class="math inline">\(\vec b \sim
N_{m+1}(\pmb\beta, \sigma^2(\vec C^T\vec C)^{-1})\)</span>，可以得知
<span class="math inline">\(\vec b\)</span> 是 <span
class="math inline">\(\pmb\beta\)</span>
的无偏估计量，还是方差最小的无偏估计（这一点不会证明）</p>
<p>方差 <span class="math inline">\(\sigma^2\)</span> 估计：残差平方和为
<span class="math inline">\(Q(\vec b)\)</span>，在这之中，有 <span
class="math inline">\(n\)</span> 个样本，但 <span
class="math inline">\(\vec b\)</span> 中已有 <span
class="math inline">\(m+1\)</span> 个参数，因此自由度为 <span
class="math inline">\(n - m - 1\)</span></p>
<p><span class="math inline">\(\sigma^2\)</span> 的无偏估计量为 <span
class="math inline">\(s^2 = \frac{Q(\vec b)}{n - m - 1}\)</span>
（这边还没彻底理解），这也就是常说的MSE。</p>
<p>如何衡量一个回归的好坏？ <span class="math display">\[
\begin{gather*}
SSE = (\vec Y - \vec{\hat Y})^T(\vec Y - \vec{\hat Y}) = Q(\vec b) \\
SSM = (\vec{\hat Y} - \overline Y)^T(\vec Y - \overline Y) \\
SST = (\vec Y - \overline Y)^T(\vec Y - \overline Y) \\
SST = SSM + SSE
\end{gather*}
\]</span> 这里的 <span class="math inline">\(SSE\)</span>
衡量了无法被回归方程解释的误差平方和，<span
class="math inline">\(SST\)</span> 为总方差，决定系数 <span
class="math inline">\(R^2 = SSM / SST\)</span>
衡量了线性回归拟合的好坏，这是一个比例，其中 <span
class="math inline">\(R\)</span> 为复相关系数。</p>
<p>为了简便上面简写成了广播的形式，向量减去 <span
class="math inline">\(\overline Y\)</span> 时应逐位操作。</p>
<h3 id="距离判别">距离判别</h3>
<p>设有 <span class="math inline">\(m\)</span> 维总体 <span
class="math inline">\(G\)</span>，已知其均值向量 <span
class="math inline">\(\pmb\mu\)</span> 和协方差矩阵 <span
class="math inline">\(\Sigma\)</span>，则样本 <span
class="math inline">\(\vec X_{m\times 1}\)</span> 到该总体的马氏距离为：
<span class="math display">\[
d^2(\vec X, G) = (\vec X - \pmb\mu)^T\Sigma^{-1} (\vec X - \pmb\mu)
\]</span> 一维情况下的马氏距离为简单的“距离平方比方差”：<span
class="math inline">\(d^2 = \frac{(x-\mu)^2}{\sigma^2}\)</span></p>
<p>若不知道精确的 <span class="math inline">\(\pmb\mu\)</span> 和 <span
class="math inline">\(\Sigma\)</span>，而是给出了总体 <span
class="math inline">\(G\)</span> 的 <span
class="math inline">\(n\)</span> 个训练样本，则可以先估计 <span
class="math inline">\(\pmb\mu\)</span> 和 <span
class="math inline">\(\Sigma\)</span>，再计算马氏距离。</p>
<p>给定多个总体 <span class="math inline">\(G_1,..G_k\)</span>
时，可以分别计算待测样本到他们的马氏距离。</p>
<p>给定 <span class="math inline">\(k\)</span>
个总体各自的样本，样本总数为 <span
class="math inline">\(n\)</span>，假设各个总体的真实协方差相同，则合并样本协方差矩阵的估计为：
<span class="math display">\[
\vec S = \frac{1}{n-k} \sum_{i=1}^k \vec A_i
\]</span> 这里 <span class="math inline">\(\vec A\)</span>
是离差阵，这个式子等价于简单地将样本合并再计算，但更加简单。因为使用了
<span class="math inline">\(k\)</span>
个均值，所以计算方差时自由度需要减 <span
class="math inline">\(k\)</span>；若合并样本后只计算一个均值，就是经典公式
<span class="math inline">\(\vec S = \frac{1}{n-1} \vec A\)</span>。
<span class="math display">\[
\begin{gather*}
d^2(\vec X, G_i) &amp;=&amp; (\vec X - \pmb\mu_i)^T \vec S^{-1} (\vec X
- \pmb\mu_i) \\
&amp;=&amp; \vec X^T \vec S^{-1}\vec X - 2(\vec X^T\vec S^{-1}\pmb\mu_i
- \frac{1}{2}\pmb\mu_i^T\vec S^{-1}\pmb\mu_i) \\
Y_i(\vec X) &amp;=&amp; 2(\vec X^T\vec S^{-1}\pmb\mu_i -
\frac{1}{2}\pmb\mu_i^T\vec S^{-1}\pmb\mu_i)
\end{gather*}
\]</span> 进行分类时，只需要对比 <span class="math inline">\(Y\)</span>
即可（虽然感觉这个 <span class="math inline">\(Y\)</span>
明明更复杂了...）。这里的 <span class="math inline">\(\pmb\mu_i\)</span>
指的是估计量。</p>
<p>进行二分类（例如 <span
class="math inline">\(G_1,G_2\)</span>），考虑两个距离之差： <span
class="math display">\[
W(\vec X) = Y_1(\vec X) - Y_2(\vec X) = (\vec X - \frac{1}{2}(\pmb\mu_1
+\pmb\mu_2))^T\vec S^{-1} (\pmb\mu_1 - \pmb\mu_2)
\]</span> 这个 <span class="math inline">\(W(\vec X)\)</span>
即为一条划分直线。注意 <span class="math inline">\(Y\)</span>
与距离是反相关的，<span class="math inline">\(W &gt; 0\)</span> 说明
<span class="math inline">\(G_1\)</span> 距离更近。</p>
<p><strong>广义距离判别</strong></p>
<p>在原先的马氏距离 <span class="math inline">\(d^2\)</span>
基础上，额外加上：</p>
<ul>
<li>一个修正损失 <span class="math inline">\(g_1(G_i) = log(|\vec
S_i|)\)</span>，这是对各组协方差不等的情况做的一个修正，不太懂有啥用。</li>
<li>先验损失 <span class="math inline">\(g_2(G_i) =
-2log(|q_i|)\)</span>，其中 <span class="math inline">\(q_i\)</span>
为第 <span class="math inline">\(i\)</span>
类出现的先验概率（可以是经验值或者所有样本中第 <span
class="math inline">\(i\)</span> 类出现的频率）</li>
</ul>
<h3 id="聚类分析">聚类分析</h3>
<p>有 <span class="math inline">\(n\)</span> 个 <span
class="math inline">\(m\)</span>
维样本，但并没有分类，需要将它们根据相似性归为几类。</p>
<p>样本间距离的度量有很多种：</p>
<ul>
<li><p>闵可夫斯基距离（包括欧氏距离，曼哈顿距离等等）</p></li>
<li><p>马氏距离，样本间的马氏距离和样本到总体的马氏距离类似： <span
class="math display">\[
d^2(\vec X_i, \vec X_j) = (\vec X_i - \vec X_j)^T\vec S^{-1} (\vec X_i -
\vec X_j)
\]</span> 其中 <span class="math inline">\(\vec S\)</span>
是通过所有样本估计得到的协方差矩阵。马氏距离不会受到各个维度的量纲影响，且考虑了方差。</p></li>
<li><p>斜交空间距离： <span class="math display">\[
d^2_{i,j} = \frac{1}{m^2}\sum_{k=1}^m \sum_{l=1}^m (x_{i,k} -
x_{i,k})(x_{i,l} - x_{j,l})r_{k,l}
\]</span> 其中 <span class="math inline">\(r_{k,l}\)</span>
为两个维度的相关系数。</p></li>
<li><p>定性样本间的距离：<span
class="math inline">\(\frac{不匹配项目数}{总项目数}\)</span>，也可以对1-1配对和0-0配对赋予不同的权重。</p></li>
<li><p>余弦相似度：<span class="math inline">\(\frac{\vec A \cdot \vec
B}{||\vec A||\times ||\vec B||}\)</span>，等等</p></li>
</ul>
<p><strong>系统聚类法</strong>：先将 <span
class="math inline">\(n\)</span> 个样本视为 <span
class="math inline">\(n\)</span>
个不同类，再不断合并最近的两类。每次合并后，需要更新合并类到其他类的距离（样本集距离）</p>
<p>两个样本集之间的距离也有很多度量，如最小样本距离、最大样本距离、类平均（两两距离的平方的均值）等；这三种距离度量都具有单调性，即每次合并后，下一次合并时的距离不会更小。</p>
<h3 id="线性规划">线性规划</h3>
<p>一个带约束的优化问题的基本形式： <span class="math display">\[
\left\{
\begin{aligned}
min \quad &amp;f(\vec x) \\
s.t. \quad &amp;h_i(\vec x) = 0 \\
&amp;g_j(\vec x) \ge 0
\end{aligned}
\right.
\]</span>
目标可以是最大或最小值，约束可以有等式约束和不等式约束。目标函数和约束都是线性函数的规划问题称为线性规划（LP）</p>
<h4 id="线性规划标准化">线性规划标准化</h4>
<p>线性规划的标准型： <span class="math display">\[
\left\{
\begin{aligned}
min \quad &amp;z = \sum_{j=1}^n c_j x_j  \\
s.t. \quad &amp;\sum_{j=1}^n a_{ij} x_j = b_i, &amp;\forall i=1,..m
&amp;(共m条约束)\\
&amp;x_j \ge 0, &amp;\forall j=1,..n &amp;
\end{aligned}
\right.
\]</span> 一般的线性规划问题可以标准化，通过下面几种方式：</p>
<ul>
<li>对于目标函数是 <span class="math inline">\(max\)</span> 的，转化求
<span class="math inline">\(min \quad f = -z\)</span></li>
<li>将约束 <span class="math inline">\(x_j \ge h\)</span> 转化为 <span
class="math inline">\(y_j = x_j - h_j \ge 0\)</span>，用 <span
class="math inline">\(y_j\)</span> 替换原变量 <span
class="math inline">\(x_j\)</span></li>
<li>将不受限的变量 <span class="math inline">\(x_j\)</span> 替换为 <span
class="math inline">\(x_j = y_j&#39; - y_j&#39;&#39;, \quad
y_j&#39;,y_j&#39;&#39; \ge 0\)</span></li>
<li>将约束 <span class="math inline">\(\sum_{j=1}^n a_{ij} x_j \le
b_i\)</span> 转化为 <span class="math inline">\(\sum_{j=1}^n a_{ij} x_j
+x_i&#39; = b_i, \quad x_i&#39; \ge 0\)</span></li>
<li>将约束 <span class="math inline">\(\sum_{j=1}^n a_{ij} x_j \ge
b_i\)</span> 转化为 <span class="math inline">\(\sum_{j=1}^n a_{ij} x_j
- x_i&#39; = b_i, \quad x_i&#39; \ge 0\)</span></li>
</ul>
<p>线性规划标准型可以写成线性方程组： <span class="math display">\[
\left\{
\begin{aligned}
min \quad &amp;z = \vec c^T \vec x\\
s.t. \quad &amp;\vec A_{m\times n}\vec x_{n\times 1} = \vec B_{m\times
1}\\
&amp;\vec x \ge 0,
\end{aligned}
\right.
\]</span> 线性方程组 <span class="math inline">\(\vec A\vec x = \vec
B\)</span> 的非负解为基本可行解。</p>
<h4 id="单纯型法">单纯型法</h4>
<p>寻找一个标准型的线性规划的最优解。</p>
<p>设矩阵 <span class="math inline">\(\vec A\)</span> 的秩为 <span
class="math inline">\(m\)</span>，即 <span
class="math inline">\(m\)</span> 条约束线性无关，且 <span
class="math inline">\(n\ge m\)</span>，则方程 <span
class="math inline">\(\vec A\vec x = \vec B\)</span> 的解系中会有 <span
class="math inline">\(n-m\)</span> 个自由变量。</p>
<p>首先先选择 <span class="math inline">\(m\)</span>
个变量作为基变量，<span class="math inline">\(n-m\)</span>
个作为自由变量，不失一般性地，假设 <span
class="math inline">\(x_{j=1,..m}\)</span>
是基变量，剩下的是自由变量。</p>
<p>基变量可以由自由变量表示，自然，目标函数也可以用自由变量表示，经过一通变换，可以弄成这种形式：</p>
<p><img src="https://lxtyin.ac.cn/img/math/dcx1.png" srcset="/img/loading.gif" lazyload /></p>
<p>这里 <span class="math inline">\(x_1,
x_2,x_3\)</span>（前三列）为基向量，最后一行为目标函数，都仅用自由变量表示。当自由变量全为0时，有
<span class="math inline">\(z = -d\)</span>；</p>
<p>若最后一行的 <span class="math inline">\(s_1,
s_2..\)</span>（即目标函数用自由变量表示时的系数）全为正，则 <span
class="math inline">\(z=-d\)</span> 是最优解（无法再小，因为任意 <span
class="math inline">\(x\ge 0\)</span>）。</p>
<p>当 <span class="math inline">\(s\)</span>
中存在负数时，可以更换基变量；具体来说，可以选择最小的 <span
class="math inline">\(s\)</span>（例如 <span
class="math inline">\(s_j\)</span>）所在的列作为新的基变量。替换原有哪一个基变量
<span class="math inline">\(i\)</span>，则取决于替换谁能使 <span
class="math inline">\(d\)</span> 更大（通常是比较 <span
class="math inline">\(\frac{b_i}{a_{ij}}\)</span>）；倒腾后可能会变成这样：</p>
<p><img src="https://lxtyin.ac.cn/img/math/dcx2.png" srcset="/img/loading.gif" lazyload /></p>
<p>经过若干轮，直到 <span class="math inline">\(s\)</span>
全为正为止，说明找到了最优解。</p>
<h4 id="凸集和凸函数">凸集和凸函数</h4>
<p><strong>凸集：</strong>集合 $D R^n $ 对于任意集合内元素 <span
class="math inline">\(\vec x, \vec y\in D\)</span>，对于任意 <span
class="math inline">\(\lambda \in[0, 1]\)</span>，有 <span
class="math inline">\(\lambda\vec x+(1-\lambda)\vec y\in D\)</span>，则
<span class="math inline">\(D\)</span>
为凸集（集合内任意两点连线的不会离开集合）。</p>
<p><strong>凸函数：</strong>定义域 <span
class="math inline">\(D\)</span> 是凸集，并且对于任意 <span
class="math inline">\(\vec x,\vec y\)</span> 和 <span
class="math inline">\(\lambda \in [0, 1]\)</span>，有 <span
class="math inline">\(\lambda f(\vec x)+(1-\lambda)f(\vec y) \ge
f(\lambda \vec x+(1-\lambda)\vec
y)\)</span>；即函数在任意方向上都是一维凸函数（两点连线永远高于函数曲线，这里的凸是指向下凸，比如
<span class="math inline">\(y=x^2\)</span>）。</p>
<p>导数定义：函数 <span class="math inline">\(f(\vec x)\)</span>
在凸集上可微，对于任意 <span class="math inline">\(\vec x,\vec
y\)</span>，有 <span class="math inline">\(f(\vec y) \ge f(\vec x) +
\nabla f(\vec x)^T(\vec y - \vec
x)\)</span>；式子右半边的部分其实就是方向导数乘上距离，可以类比一维情况。</p>
<p>二阶导定义：函数 <span class="math inline">\(f(\vec x)\)</span>
在任意位置的Hessian矩阵半正定（即任意方向二阶导大于0），也是凸函数的充要条件。</p>
<p>凸函数的线性组合仍然是凸函数；对凸函数进行截断 <span
class="math inline">\(\{ \vec x| f(\vec x) &lt;\beta\}\)</span>
是凸集。</p>
<h3 id="无约束的非线性规划">无约束的非线性规划</h3>
<p>这类问题是要求非线性函数的极值点，通常需要数值解法，例如梯度下降等。</p>
<h4 id="最速下降">最速下降</h4>
<p>即理论最快的梯度下降，需要目标函数 <span class="math inline">\(f(\vec
x)\)</span> 的可导解析解。</p>
<p>在第 <span class="math inline">\(k\)</span> 步，当前位置为 <span
class="math inline">\(\vec x^{(k)}\)</span>，下一步移动方向为 <span
class="math inline">\(d^{(k)} = -\nabla f(\vec
x^{(k)})\)</span>，下一步的位置为 <span class="math inline">\(\vec
x^{(k+1)} = \vec x^{(k)} + a^{(k)}d^{(k)}\)</span></p>
<p>最速下降希望控制每一步的 <span
class="math inline">\(a^{(k)}\)</span>，让每一步都直达谷底，即 <span
class="math inline">\(a^{(k)} = \arg \min(f(\vec x^{(k)} +
a^{(k)}d^{(k)}))\)</span>，那么它的一阶导为0： <span
class="math display">\[
\frac{\partial f(\vec x^{(k)} + a^{(k)}d^{(k)})}{\partial a^{(k)}} =
d^{(k)^T}\nabla f(\vec x^{(k+1)}) = 0
\]</span> <span class="math inline">\(f(\vec x)\)</span>
可导时，可以通过这个式子得到 <span
class="math inline">\(a^{(k)}\)</span>
的取值。从上式中还能看出每相邻两步的方向都是正交的。</p>
<p>注意：最速下降一步最多只能走到 <span
class="math inline">\(d^{(k)}\)</span>
方向上的极小值，不一定就是局部极小值。</p>
<h4 id="共轭梯度下降">共轭梯度下降</h4>
<p>目标函数写作 <span class="math inline">\(f(\vec x) = \frac{1}{2} \vec
x^T \vec Q \vec x\)</span>，可以再加上 <span class="math inline">\(\vec
b\vec x +c\)</span>，但不重要。</p>
<p>和最速下降类似，但每一步下降的方向不再是 <span
class="math inline">\(-\nabla f(\vec x^{(k)})\)</span>，而是 <span
class="math inline">\(p_k\)</span>，这些 <span
class="math inline">\(p\)</span> 构成一组基底，且满足： <span
class="math display">\[
p_i^T \vec Qp_j = 0,(i\neq j)
\]</span> 它们被称为关于 <span class="math inline">\(\vec
Q-共轭\)</span>，<span class="math inline">\(p\)</span>
也是迭代法构造的，初始 <span class="math inline">\(p_0 = -\nabla f(\vec
x^{(0)})\)</span>，在第 <span class="math inline">\(k\)</span> 步，已知
<span class="math inline">\(\vec x^{(k)}\)</span> 和 <span
class="math inline">\(p_k\)</span>，接下来： <span
class="math display">\[
\begin{gather*}
\vec x^{(k+1)} = \vec x^{(k)} + a^{(k)}p_k \\
p_{k+1} = -\nabla f(\vec x^{(k+1)}) + \lambda^{(k)} p_k
\end{gather*}
\]</span> <span class="math inline">\(a\)</span>
的推导和最速下降法相同，<span class="math inline">\(p\)</span> 则由
<span class="math inline">\(p_k^T \vec Qp_{k+1} = 0\)</span>
确定，结论是： <span class="math display">\[
\lambda^{(k)} = \frac{p_k^T \vec Q \nabla f(\vec x^{(k+1)})}{p_k^T \vec
Qp_k}
\]</span> 用共轭梯度下降的理由是，<span class="math inline">\(\vec
x\)</span> 用 <span class="math inline">\(p\)</span>
基表示，原目标函数可以拆成分离变量的形式： <span class="math display">\[
f(\vec x) = \frac{1}{2} (\sum a_ip_i)^T \vec Q(\sum a_ip_i) =
\frac{1}{2}\sum a_i^2p_i^T\vec Q p_i
\]</span> 然后可以在每一个方向上独立下降。但实际做法上 <span
class="math inline">\(p\)</span>
是迭代产生的，感觉会比最速下降更复杂。</p>
<h4 id="牛顿法">牛顿法</h4>
<p>一维函数的牛顿法： <span class="math display">\[
x^{(k+1)} = x^{(k)} - \frac{f&#39;(x^{(k)})}{f&#39;&#39;(x^{(k)})}
\]</span> 多元函数： <span class="math display">\[
\vec x^{(k+1)} = \vec x^{(k)} - \frac{\nabla f(\vec x^{(k)})}{\nabla
^2f(\vec x^{(k)})} = \vec x^{(k)} - \vec H(\vec x^{(k)})^{-1}\nabla
f(\vec x^{(k)})
\]</span> 多元函数的一阶导是梯度，二阶导是Hessian矩阵。</p>
<h4 id="拟牛顿法">拟牛顿法</h4>
<p>在牛顿法中，求Hessian矩阵及其逆很慢，因此希望近似 <span
class="math inline">\(H_k \approx \vec H(x^{(k)})^{-1}\)</span></p>
<p>这里直接给出其近似方案，具体推导不想看了） $$ <span
class="math display">\[\begin{gather*}
H_0 = \vec I \\
H_{k+1} = H_k + \frac{\delta_{k+1} \delta_{k+1}^T}{\delta_{k+1}^T
\gamma_{k+1}} - \frac{ H_k\gamma_{k+1} \gamma_{k+1}^T H_k}{
\gamma_{k+1}^T  H_k\gamma_{k+1}} \\
\delta_{k+1} = \vec x^{(k+1)} - \vec x^{(k)} \\
\gamma_{k+1} = \nabla f(\vec x^{(k+1)}) - \nabla f(\vec x^{(k)})

\end{gather*}\]</span> <span class="math display">\[
每一步的更新为：
\]</span> x^{(k+1)} = x^{(k)} + a^{(k)}(-H_k f(x^{(k)})) $$
到这里，<span class="math inline">\(a\)</span>
的计算又和最速下降一样了。</p>
<h3 id="约束优化">约束优化</h3>
<h4 id="消去等式约束">消去等式约束</h4>
<p><span class="math display">\[
\left\{
\begin{aligned}
min \quad &amp;f(\vec x) \\
s.t. \quad &amp;h_i(\vec x) = 0 \\
&amp;g_j(\vec x) \ge 0
\end{aligned}
\right.
\]</span></p>
<p>等式约束通过转换去掉，添加额外的优化变量 <span
class="math inline">\(\lambda &gt; 0\)</span>，新的优化目标为： <span
class="math display">\[
L(\vec x, \pmb\lambda) = f(\vec x) + \sum \lambda_i h_i(\vec x)
\]</span> 通过这种转换，原先的最优解在新的域下也一定是最优解</p>
<p><strong>拉格朗日乘子法</strong>：对于仅含有等式约束的问题，可以转换成上面的优化目标
<span class="math inline">\(L(\vec x,
\pmb\lambda)\)</span>，并根据其一阶导（包括 <span
class="math inline">\(\frac{\partial L}{\partial \vec x}, \frac{\partial
L}{\partial
\pmb\lambda}\)</span>）为0推出极小值（是不是不一定能推得出来？）</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E7%AC%94%E8%AE%B0/" class="category-chain-item">笔记</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%95%B0%E7%90%86%E5%9F%BA%E7%A1%80/">#数理基础</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>专业数学基础</div>
      <div>http://www.lxtyin.ac.cn/2024/12/06/专业数学基础/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>lx_tyin</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年12月6日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'lxtyin/lxtyin.github.io.comments');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-left: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="笔记"
        id="heading-7051dc52c184c205e39aa54b4664ae9b" role="tab" data-toggle="collapse" href="#collapse-7051dc52c184c205e39aa54b4664ae9b"
        aria-expanded="true"
      >
        笔记
        <span class="list-group-count">(13)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-7051dc52c184c205e39aa54b4664ae9b"
           role="tabpanel" aria-labelledby="heading-7051dc52c184c205e39aa54b4664ae9b">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2024/11/27/%E7%AC%94%E8%AE%B0/Microfacet%20model%E6%A6%82%E8%BF%B0/" title="Microfacet model概述（监修中）"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Microfacet model概述（监修中）</span>
        </a>
      
    
      
      
        <a href="/2023/02/26/%E7%AC%94%E8%AE%B0/openGL%E5%85%A5%E9%97%A8/" title="OpenGL入门"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">OpenGL入门</span>
        </a>
      
    
      
      
        <a href="/2023/03/15/%E7%AC%94%E8%AE%B0/ReSTIR%E7%AC%94%E8%AE%B0/" title="ReSTIR学习笔记"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">ReSTIR学习笔记</span>
        </a>
      
    
      
      
        <a href="/2024/11/29/%E7%AC%94%E8%AE%B0/Volume%20Rendering%E7%AC%94%E8%AE%B0/" title="Volume rendering概述"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Volume rendering概述</span>
        </a>
      
    
      
      
        <a href="/2022/04/02/%E7%AC%94%E8%AE%B0/git%E8%BF%9B%E9%98%B6/" title="git进阶"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">git进阶</span>
        </a>
      
    
      
      
        <a href="/2024/12/06/%E4%B8%93%E4%B8%9A%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/" title="专业数学基础"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">专业数学基础</span>
        </a>
      
    
      
      
        <a href="/2023/02/26/%E7%AC%94%E8%AE%B0/%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA%E5%85%A5%E9%97%A8/" title="光线追踪入门"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">光线追踪入门</span>
        </a>
      
    
      
      
        <a href="/2023/02/26/%E7%AC%94%E8%AE%B0/%E5%87%A0%E4%BD%95%E6%9D%82%E8%AE%B0/" title="几何杂记"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">几何杂记</span>
        </a>
      
    
      
      
        <a href="/2023/09/22/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%9D%82%E8%AE%B0/" title="图形学杂记"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">图形学杂记</span>
        </a>
      
    
      
      
        <a href="/2022/11/16/%E7%AC%94%E8%AE%B0/%E6%AC%A7%E6%8B%89%E8%A7%92%E3%80%81%E9%A1%BA%E8%A7%84%E3%80%81%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5%E3%80%81%E5%9B%9B%E5%85%83%E6%95%B0/" title="欧拉角、顺规、旋转矩阵、四元数"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">欧拉角、顺规、旋转矩阵、四元数</span>
        </a>
      
    
      
      
        <a href="/categories/%E7%AC%94%E8%AE%B0/" class="list-group-item list-group-item-action">
          <span class="category-post">More...</span>
        </a>
        
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
